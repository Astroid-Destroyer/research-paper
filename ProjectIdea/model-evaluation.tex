\subsection{Model Evaluation}

The data set is divided into a 70: 30 ratio of training and test data set using the scikit learn library of the python language. Along with this perplexity score is used for further evaluation.Perplexity (PPL) is a popular metric for evaluating language models. \cite{BanglaGPT:1}Perplexity is defined as a sequence of exponential average negative log-likelihood. If we have a tokenized sequence

\begin{align*}
    Y      & = (y_0, y_1, y_2, \ldots, y_t)                                                \\
    \text{then the perplexity of } Y \text{ is, }                                          \\
    PPL(Y) & = \exp\left(-\frac{1}{t} \sum_{i=1}^{t} \log p_{\Phi}(y_i \mid y_{<i})\right)
\end{align*}
In the context of language models, a lower perplexity score is usually preferable.